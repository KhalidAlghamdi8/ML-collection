{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model using CNN - Sequential API \n",
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(32,32,3)),\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu'), \n",
    "    layers.MaxPool2D(pool_size=(2,2)), \n",
    "    layers.Conv2D(64, 3, activation='relu'), \n",
    "    layers.MaxPool2D(),\n",
    "    layers.Conv2D(128, 3, activation='relu'), \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10), \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 - 3s - loss: 1.6118 - accuracy: 0.4151\n",
      "Epoch 2/10\n",
      "782/782 - 3s - loss: 1.2717 - accuracy: 0.5490\n",
      "Epoch 3/10\n",
      "782/782 - 2s - loss: 1.1382 - accuracy: 0.5994\n",
      "Epoch 4/10\n",
      "782/782 - 2s - loss: 1.0425 - accuracy: 0.6355\n",
      "Epoch 5/10\n",
      "782/782 - 3s - loss: 0.9580 - accuracy: 0.6650\n",
      "Epoch 6/10\n",
      "782/782 - 2s - loss: 0.8988 - accuracy: 0.6870\n",
      "Epoch 7/10\n",
      "782/782 - 2s - loss: 0.8446 - accuracy: 0.7086\n",
      "Epoch 8/10\n",
      "782/782 - 2s - loss: 0.7999 - accuracy: 0.7257\n",
      "Epoch 9/10\n",
      "782/782 - 2s - loss: 0.7556 - accuracy: 0.7393\n",
      "Epoch 10/10\n",
      "782/782 - 2s - loss: 0.7168 - accuracy: 0.7528\n",
      "157/157 - 0s - loss: 0.8515 - accuracy: 0.7062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8515331745147705, 0.7062000036239624]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=3e-4), \n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "model.fit(x_train,y_train, batch_size=64,epochs=10,verbose=2)\n",
    "model.evaluate(x_test,y_test, batch_size=64,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 5, 5, 128)         73856     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                204864    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 298,762\n",
      "Trainable params: 298,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Regularization with L2 and Dropout\n",
    "\n",
    "def my_model():\n",
    "    inputs = keras.Input(shape=(32, 32, 3))\n",
    "    x = layers.Conv2D(32, 3, padding=\"same\", kernel_regularizer=regularizers.l2(0.01),)(\n",
    "        inputs\n",
    "    )\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\", kernel_regularizer=regularizers.l2(0.01),)(\n",
    "        x\n",
    "    )\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(\n",
    "        128, 3, padding=\"same\", kernel_regularizer=regularizers.l2(0.01),\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01),)(\n",
    "        x\n",
    "    )\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(10)(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kalgh\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "782/782 - 4s - loss: 2.9994 - accuracy: 0.3424\n",
      "Epoch 2/150\n",
      "782/782 - 3s - loss: 1.8959 - accuracy: 0.4656\n",
      "Epoch 3/150\n",
      "782/782 - 4s - loss: 1.6289 - accuracy: 0.5062\n",
      "Epoch 4/150\n",
      "782/782 - 3s - loss: 1.5178 - accuracy: 0.5329\n",
      "Epoch 5/150\n",
      "782/782 - 4s - loss: 1.4516 - accuracy: 0.5502\n",
      "Epoch 6/150\n",
      "782/782 - 4s - loss: 1.4066 - accuracy: 0.5662\n",
      "Epoch 7/150\n",
      "782/782 - 4s - loss: 1.3797 - accuracy: 0.5792\n",
      "Epoch 8/150\n",
      "782/782 - 4s - loss: 1.3459 - accuracy: 0.5888\n",
      "Epoch 9/150\n",
      "782/782 - 4s - loss: 1.3296 - accuracy: 0.5931\n",
      "Epoch 10/150\n",
      "782/782 - 4s - loss: 1.3107 - accuracy: 0.6061\n",
      "Epoch 11/150\n",
      "782/782 - 3s - loss: 1.2982 - accuracy: 0.6105\n",
      "Epoch 12/150\n",
      "782/782 - 4s - loss: 1.2797 - accuracy: 0.6150\n",
      "Epoch 13/150\n",
      "782/782 - 4s - loss: 1.2668 - accuracy: 0.6238\n",
      "Epoch 14/150\n",
      "782/782 - 4s - loss: 1.2599 - accuracy: 0.6251\n",
      "Epoch 15/150\n",
      "782/782 - 4s - loss: 1.2435 - accuracy: 0.6328\n",
      "Epoch 16/150\n",
      "782/782 - 3s - loss: 1.2401 - accuracy: 0.6364\n",
      "Epoch 17/150\n",
      "782/782 - 4s - loss: 1.2276 - accuracy: 0.6410\n",
      "Epoch 18/150\n",
      "782/782 - 4s - loss: 1.2226 - accuracy: 0.6436\n",
      "Epoch 19/150\n",
      "782/782 - 4s - loss: 1.2152 - accuracy: 0.6463\n",
      "Epoch 20/150\n",
      "782/782 - 3s - loss: 1.2027 - accuracy: 0.6487\n",
      "Epoch 21/150\n",
      "782/782 - 3s - loss: 1.1962 - accuracy: 0.6554\n",
      "Epoch 22/150\n",
      "782/782 - 4s - loss: 1.1891 - accuracy: 0.6574\n",
      "Epoch 23/150\n",
      "782/782 - 3s - loss: 1.1837 - accuracy: 0.6616\n",
      "Epoch 24/150\n",
      "782/782 - 3s - loss: 1.1709 - accuracy: 0.6671\n",
      "Epoch 25/150\n",
      "782/782 - 3s - loss: 1.1611 - accuracy: 0.6734\n",
      "Epoch 26/150\n",
      "782/782 - 3s - loss: 1.1560 - accuracy: 0.6749\n",
      "Epoch 27/150\n",
      "782/782 - 3s - loss: 1.1529 - accuracy: 0.6762\n",
      "Epoch 28/150\n",
      "782/782 - 3s - loss: 1.1482 - accuracy: 0.6785\n",
      "Epoch 29/150\n",
      "782/782 - 3s - loss: 1.1435 - accuracy: 0.6811\n",
      "Epoch 30/150\n",
      "782/782 - 3s - loss: 1.1344 - accuracy: 0.6846\n",
      "Epoch 31/150\n",
      "782/782 - 3s - loss: 1.1298 - accuracy: 0.6908\n",
      "Epoch 32/150\n",
      "782/782 - 4s - loss: 1.1241 - accuracy: 0.6909\n",
      "Epoch 33/150\n",
      "782/782 - 4s - loss: 1.1219 - accuracy: 0.6921\n",
      "Epoch 34/150\n",
      "782/782 - 4s - loss: 1.1237 - accuracy: 0.6922\n",
      "Epoch 35/150\n",
      "782/782 - 4s - loss: 1.1173 - accuracy: 0.6955\n",
      "Epoch 36/150\n",
      "782/782 - 4s - loss: 1.1054 - accuracy: 0.7019\n",
      "Epoch 37/150\n",
      "782/782 - 4s - loss: 1.1073 - accuracy: 0.7016\n",
      "Epoch 38/150\n",
      "782/782 - 4s - loss: 1.0928 - accuracy: 0.7051\n",
      "Epoch 39/150\n",
      "782/782 - 4s - loss: 1.0987 - accuracy: 0.7080\n",
      "Epoch 40/150\n",
      "782/782 - 3s - loss: 1.0912 - accuracy: 0.7079\n",
      "Epoch 41/150\n",
      "782/782 - 4s - loss: 1.0909 - accuracy: 0.7081\n",
      "Epoch 42/150\n",
      "782/782 - 4s - loss: 1.0834 - accuracy: 0.7133\n",
      "Epoch 43/150\n",
      "782/782 - 4s - loss: 1.0816 - accuracy: 0.7119\n",
      "Epoch 44/150\n",
      "782/782 - 4s - loss: 1.0812 - accuracy: 0.7139\n",
      "Epoch 45/150\n",
      "782/782 - 4s - loss: 1.0768 - accuracy: 0.7159\n",
      "Epoch 46/150\n",
      "782/782 - 3s - loss: 1.0654 - accuracy: 0.7183\n",
      "Epoch 47/150\n",
      "782/782 - 3s - loss: 1.0693 - accuracy: 0.7158\n",
      "Epoch 48/150\n",
      "782/782 - 3s - loss: 1.0621 - accuracy: 0.7198\n",
      "Epoch 49/150\n",
      "782/782 - 3s - loss: 1.0582 - accuracy: 0.7232\n",
      "Epoch 50/150\n",
      "782/782 - 3s - loss: 1.0582 - accuracy: 0.7223\n",
      "Epoch 51/150\n",
      "782/782 - 4s - loss: 1.0578 - accuracy: 0.7223\n",
      "Epoch 52/150\n",
      "782/782 - 4s - loss: 1.0577 - accuracy: 0.7248\n",
      "Epoch 53/150\n",
      "782/782 - 3s - loss: 1.0533 - accuracy: 0.7226\n",
      "Epoch 54/150\n",
      "782/782 - 4s - loss: 1.0417 - accuracy: 0.7269\n",
      "Epoch 55/150\n",
      "782/782 - 3s - loss: 1.0426 - accuracy: 0.7274\n",
      "Epoch 56/150\n",
      "782/782 - 4s - loss: 1.0450 - accuracy: 0.7274\n",
      "Epoch 57/150\n",
      "782/782 - 4s - loss: 1.0399 - accuracy: 0.7264\n",
      "Epoch 58/150\n",
      "782/782 - 4s - loss: 1.0350 - accuracy: 0.7305\n",
      "Epoch 59/150\n",
      "782/782 - 4s - loss: 1.0329 - accuracy: 0.7344\n",
      "Epoch 60/150\n",
      "782/782 - 4s - loss: 1.0367 - accuracy: 0.7315\n",
      "Epoch 61/150\n",
      "782/782 - 4s - loss: 1.0317 - accuracy: 0.7351\n",
      "Epoch 62/150\n",
      "782/782 - 4s - loss: 1.0257 - accuracy: 0.7357\n",
      "Epoch 63/150\n",
      "782/782 - 4s - loss: 1.0287 - accuracy: 0.7356\n",
      "Epoch 64/150\n",
      "782/782 - 3s - loss: 1.0258 - accuracy: 0.7396\n",
      "Epoch 65/150\n",
      "782/782 - 4s - loss: 1.0182 - accuracy: 0.7392\n",
      "Epoch 66/150\n",
      "782/782 - 4s - loss: 1.0250 - accuracy: 0.7382\n",
      "Epoch 67/150\n",
      "782/782 - 4s - loss: 1.0203 - accuracy: 0.7400\n",
      "Epoch 68/150\n",
      "782/782 - 4s - loss: 1.0181 - accuracy: 0.7408\n",
      "Epoch 69/150\n",
      "782/782 - 4s - loss: 1.0153 - accuracy: 0.7405\n",
      "Epoch 70/150\n",
      "782/782 - 4s - loss: 1.0172 - accuracy: 0.7414\n",
      "Epoch 71/150\n",
      "782/782 - 4s - loss: 1.0110 - accuracy: 0.7435\n",
      "Epoch 72/150\n",
      "782/782 - 3s - loss: 1.0078 - accuracy: 0.7450\n",
      "Epoch 73/150\n",
      "782/782 - 3s - loss: 1.0129 - accuracy: 0.7454\n",
      "Epoch 74/150\n",
      "782/782 - 4s - loss: 1.0074 - accuracy: 0.7458\n",
      "Epoch 75/150\n",
      "782/782 - 3s - loss: 1.0046 - accuracy: 0.7463\n",
      "Epoch 76/150\n",
      "782/782 - 3s - loss: 1.0006 - accuracy: 0.7486\n",
      "Epoch 77/150\n",
      "782/782 - 3s - loss: 1.0055 - accuracy: 0.7462\n",
      "Epoch 78/150\n",
      "782/782 - 4s - loss: 1.0020 - accuracy: 0.7499\n",
      "Epoch 79/150\n",
      "782/782 - 3s - loss: 1.0054 - accuracy: 0.7468\n",
      "Epoch 80/150\n",
      "782/782 - 3s - loss: 1.0028 - accuracy: 0.7485\n",
      "Epoch 81/150\n",
      "782/782 - 3s - loss: 0.9890 - accuracy: 0.7533\n",
      "Epoch 82/150\n",
      "782/782 - 3s - loss: 0.9966 - accuracy: 0.7520\n",
      "Epoch 83/150\n",
      "782/782 - 3s - loss: 0.9947 - accuracy: 0.7530\n",
      "Epoch 84/150\n",
      "782/782 - 4s - loss: 0.9962 - accuracy: 0.7515\n",
      "Epoch 85/150\n",
      "782/782 - 4s - loss: 0.9911 - accuracy: 0.7560\n",
      "Epoch 86/150\n",
      "782/782 - 3s - loss: 0.9941 - accuracy: 0.7536\n",
      "Epoch 87/150\n",
      "782/782 - 4s - loss: 0.9893 - accuracy: 0.7542\n",
      "Epoch 88/150\n",
      "782/782 - 4s - loss: 0.9885 - accuracy: 0.7541\n",
      "Epoch 89/150\n",
      "782/782 - 4s - loss: 0.9861 - accuracy: 0.7552\n",
      "Epoch 90/150\n",
      "782/782 - 4s - loss: 0.9816 - accuracy: 0.7583\n",
      "Epoch 91/150\n",
      "782/782 - 4s - loss: 0.9861 - accuracy: 0.7565\n",
      "Epoch 92/150\n",
      "782/782 - 3s - loss: 0.9865 - accuracy: 0.7539\n",
      "Epoch 93/150\n",
      "782/782 - 3s - loss: 0.9804 - accuracy: 0.7587\n",
      "Epoch 94/150\n",
      "782/782 - 4s - loss: 0.9776 - accuracy: 0.7565\n",
      "Epoch 95/150\n",
      "782/782 - 3s - loss: 0.9839 - accuracy: 0.7595\n",
      "Epoch 96/150\n",
      "782/782 - 3s - loss: 0.9754 - accuracy: 0.7617\n",
      "Epoch 97/150\n",
      "782/782 - 3s - loss: 0.9815 - accuracy: 0.7595\n",
      "Epoch 98/150\n",
      "782/782 - 4s - loss: 0.9714 - accuracy: 0.7636\n",
      "Epoch 99/150\n",
      "782/782 - 3s - loss: 0.9790 - accuracy: 0.7599\n",
      "Epoch 100/150\n",
      "782/782 - 3s - loss: 0.9744 - accuracy: 0.7593\n",
      "Epoch 101/150\n",
      "782/782 - 4s - loss: 0.9720 - accuracy: 0.7595\n",
      "Epoch 102/150\n",
      "782/782 - 4s - loss: 0.9779 - accuracy: 0.7587\n",
      "Epoch 103/150\n",
      "782/782 - 3s - loss: 0.9631 - accuracy: 0.7661\n",
      "Epoch 104/150\n",
      "782/782 - 4s - loss: 0.9630 - accuracy: 0.7673\n",
      "Epoch 105/150\n",
      "782/782 - 4s - loss: 0.9734 - accuracy: 0.7629\n",
      "Epoch 106/150\n",
      "782/782 - 4s - loss: 0.9654 - accuracy: 0.7646\n",
      "Epoch 107/150\n",
      "782/782 - 4s - loss: 0.9629 - accuracy: 0.7638\n",
      "Epoch 108/150\n",
      "782/782 - 3s - loss: 0.9616 - accuracy: 0.7660\n",
      "Epoch 109/150\n",
      "782/782 - 4s - loss: 0.9681 - accuracy: 0.7633\n",
      "Epoch 110/150\n",
      "782/782 - 4s - loss: 0.9674 - accuracy: 0.7663\n",
      "Epoch 111/150\n",
      "782/782 - 3s - loss: 0.9643 - accuracy: 0.7667\n",
      "Epoch 112/150\n",
      "782/782 - 3s - loss: 0.9645 - accuracy: 0.7662\n",
      "Epoch 113/150\n",
      "782/782 - 4s - loss: 0.9726 - accuracy: 0.7662\n",
      "Epoch 114/150\n",
      "782/782 - 4s - loss: 0.9575 - accuracy: 0.7678\n",
      "Epoch 115/150\n",
      "782/782 - 4s - loss: 0.9601 - accuracy: 0.7681\n",
      "Epoch 116/150\n",
      "782/782 - 3s - loss: 0.9636 - accuracy: 0.7658\n",
      "Epoch 117/150\n",
      "782/782 - 3s - loss: 0.9566 - accuracy: 0.7709\n",
      "Epoch 118/150\n",
      "782/782 - 4s - loss: 0.9612 - accuracy: 0.7688\n",
      "Epoch 119/150\n",
      "782/782 - 4s - loss: 0.9533 - accuracy: 0.7700\n",
      "Epoch 120/150\n",
      "782/782 - 4s - loss: 0.9534 - accuracy: 0.7712\n",
      "Epoch 121/150\n",
      "782/782 - 4s - loss: 0.9545 - accuracy: 0.7716\n",
      "Epoch 122/150\n",
      "782/782 - 4s - loss: 0.9600 - accuracy: 0.7694\n",
      "Epoch 123/150\n",
      "782/782 - 4s - loss: 0.9585 - accuracy: 0.7684\n",
      "Epoch 124/150\n",
      "782/782 - 4s - loss: 0.9557 - accuracy: 0.7689\n",
      "Epoch 125/150\n",
      "782/782 - 4s - loss: 0.9521 - accuracy: 0.7739\n",
      "Epoch 126/150\n",
      "782/782 - 4s - loss: 0.9532 - accuracy: 0.7721\n",
      "Epoch 127/150\n",
      "782/782 - 4s - loss: 0.9509 - accuracy: 0.7724\n",
      "Epoch 128/150\n",
      "782/782 - 4s - loss: 0.9505 - accuracy: 0.7751\n",
      "Epoch 129/150\n",
      "782/782 - 4s - loss: 0.9500 - accuracy: 0.7737\n",
      "Epoch 130/150\n",
      "782/782 - 4s - loss: 0.9513 - accuracy: 0.7736\n",
      "Epoch 131/150\n",
      "782/782 - 4s - loss: 0.9476 - accuracy: 0.7740\n",
      "Epoch 132/150\n",
      "782/782 - 3s - loss: 0.9552 - accuracy: 0.7707\n",
      "Epoch 133/150\n",
      "782/782 - 3s - loss: 0.9601 - accuracy: 0.7724\n",
      "Epoch 134/150\n",
      "782/782 - 3s - loss: 0.9518 - accuracy: 0.7713\n",
      "Epoch 135/150\n",
      "782/782 - 3s - loss: 0.9496 - accuracy: 0.7744\n",
      "Epoch 136/150\n",
      "782/782 - 3s - loss: 0.9514 - accuracy: 0.7749\n",
      "Epoch 137/150\n",
      "782/782 - 3s - loss: 0.9495 - accuracy: 0.7740\n",
      "Epoch 138/150\n",
      "782/782 - 3s - loss: 0.9442 - accuracy: 0.7743\n",
      "Epoch 139/150\n",
      "782/782 - 3s - loss: 0.9508 - accuracy: 0.7740\n",
      "Epoch 140/150\n",
      "782/782 - 3s - loss: 0.9482 - accuracy: 0.7776\n",
      "Epoch 141/150\n",
      "782/782 - 4s - loss: 0.9493 - accuracy: 0.7769\n",
      "Epoch 142/150\n",
      "782/782 - 4s - loss: 0.9526 - accuracy: 0.7733\n",
      "Epoch 143/150\n",
      "782/782 - 4s - loss: 0.9413 - accuracy: 0.7775\n",
      "Epoch 144/150\n",
      "782/782 - 3s - loss: 0.9490 - accuracy: 0.7752\n",
      "Epoch 145/150\n",
      "782/782 - 4s - loss: 0.9518 - accuracy: 0.7778\n",
      "Epoch 146/150\n",
      "782/782 - 4s - loss: 0.9470 - accuracy: 0.7750\n",
      "Epoch 147/150\n",
      "782/782 - 4s - loss: 0.9482 - accuracy: 0.7769\n",
      "Epoch 148/150\n",
      "782/782 - 4s - loss: 0.9450 - accuracy: 0.7774\n",
      "Epoch 149/150\n",
      "782/782 - 4s - loss: 0.9496 - accuracy: 0.7763\n",
      "Epoch 150/150\n",
      "782/782 - 4s - loss: 0.9430 - accuracy: 0.7775\n",
      "157/157 - 1s - loss: 1.3787 - accuracy: 0.6985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3787013292312622, 0.6984999775886536]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = my_model()\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(lr=3e-4),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=150, verbose=2)\n",
    "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93a850cdd8e1ced0015abffd1c74857b7727d52a3b5bd3cee8894c4cf53924e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
